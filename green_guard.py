# -*- coding: utf-8 -*-
"""ufc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LpyNRlx1nUr_wJ2kA3PDPiYv5oEoKAjK
"""


import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
from pytorch_lightning import LightningModule, Trainer, LightningDataModule, callbacks
from torchvision.datasets import ImageFolder
from PIL import Image
import pytorch_lightning as pl
from sklearn.metrics import classification_report, confusion_matrix
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
import numpy as np
import matplotlib.pyplot as plt
import random
from sklearn.model_selection import GridSearchCV
 

dataset=datasets.ImageFolder(root="Rice Leaf Disease Dataset")

transform=transforms.Compose([
        transforms.RandomRotation(10),      # rotate +/- 10 degrees
        transforms.RandomHorizontalFlip(),  # reverse 50% of images
        transforms.Resize(224),             # resize shortest side to 224 pixels
        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
])

class DataModule(pl.LightningDataModule):

    def __init__(self, transform=transform, batch_size=32):
        super().__init__()
        self.root_dir = "Rice Leaf Disease Dataset"
        self.transform = transform
        self.batch_size = batch_size

    def setup(self, stage=None):
        dataset = datasets.ImageFolder(root=self.root_dir, transform=self.transform)
        n_data = len(dataset)
        n_train = int(0.7 * n_data)
        n_valid = int(0.15 * n_data)
        n_test = n_data - n_train - n_valid

        train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_valid, n_test])

        self.trainset = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
        self.validset = DataLoader(valid_dataset, batch_size=self.batch_size)
        self.testset = DataLoader(test_dataset, batch_size=self.batch_size)

    def train_dataloader(self):
        return self.trainset

    def val_dataloader(self):
        return self.validset

    def test_dataloader(self):
        return self.testset

class ConvolutionalNetwork(pl.LightningModule):
    def __init__(self, learning_rate=0.001):
        super(ConvolutionalNetwork, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 3, 1)
        self.conv2 = nn.Conv2d(6, 16, 3, 1)
        self.fc1 = nn.Linear(16 * 54 * 54, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, len(dataset.classes))
        self.learning_rate = learning_rate

    def forward(self, X):
        X = F.relu(self.conv1(X))
        X = F.max_pool2d(X, 2, 2)
        X = F.relu(self.conv2(X))
        X = F.max_pool2d(X, 2, 2)
        X = X.view(-1, 16 * 54 * 54)
        X = F.relu(self.fc1(X))
        X = F.relu(self.fc2(X))
        X = self.fc3(X)
        return F.log_softmax(X, dim=1)

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        return optimizer

    def training_step(self, train_batch, batch_idx):
        X, y = train_batch
        y_hat = self(X)
        loss = F.cross_entropy(y_hat, y)
        pred = y_hat.argmax(dim=1, keepdim=True)
        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]
        self.log("train_loss", loss)
        self.log("train_acc", acc)
        return loss

    def validation_step(self, val_batch, batch_idx):
        X, y = val_batch
        y_hat = self(X)
        loss = F.cross_entropy(y_hat, y)
        pred = y_hat.argmax(dim=1, keepdim=True)
        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]
        self.log("val_loss", loss)
        self.log("val_acc", acc)

    def test_step(self, test_batch, batch_idx):
        X, y = test_batch
        y_hat = self(X)
        loss = F.cross_entropy(y_hat, y)
        pred = y_hat.argmax(dim=1, keepdim=True)
        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]
        self.log("test_loss", loss)
        self.log("test_acc", acc)

if __name__ == "__main__":
    # Training
    datamodule = DataModule()
    datamodule.setup()

    model = ConvolutionalNetwork()
    trainer = pl.Trainer(max_epochs=50)
    trainer.fit(model, datamodule)

# Testing
    datamodule.setup(stage='test')
    test_loader = datamodule.test_dataloader()
    trainer.test(dataloaders=test_loader)

# Inference
    device = torch.device("cpu")   # or "cuda:0" if using GPU
    model.eval()
    y_true = []
    y_pred = []

    with torch.no_grad():
            for test_data in datamodule.test_dataloader():
                test_images, test_labels = test_data[0].to(device), test_data[1].to(device)
                pred = model(test_images).argmax(dim=1)
                for i in range(len(pred)):
                    y_true.append(test_labels[i].item())
                    y_pred.append(pred[i].item())

                    # Print predicted label and actual label
                    predicted_label = dataset.classes[pred[i].item()]
                    actual_label = dataset.classes[test_labels[i].item()]
                    print(f"Predicted: {predicted_label}, Actual: {actual_label}")

                    # Show the image
                    image = np.transpose(test_images[i].cpu().numpy(), (1, 2, 0))  # If the image is in CHW format, transpose it to HWC
                    plt.imshow(image)
                    plt.title(f"Predicted: {predicted_label}\nActual: {actual_label}")
                    plt.show()


    # Save the trained model
    trainer.save_checkpoint("main_model.ckpt")

    # Convert the lists of true and predicted labels into numpy arrays
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    # Generate classification report
    classification_rep = classification_report(y_true, y_pred, target_names=dataset.classes)
    print("Classification Report:")
    print(classification_rep)

    # Generate confusion matrix
    conf_matrix = confusion_matrix(y_true, y_pred)
    print("\nConfusion Matrix:")
    print(conf_matrix)

# import torch
# import requests
# from torchvision import transforms
# from PIL import Image
# from io import BytesIO

# # Define the transformation for preprocessing internet images
# transform_internet = transforms.Compose([
#     transforms.Resize((224, 224)),         # Resize the image to 224x224
#     transforms.CenterCrop(224),           # Center crop the image
#     transforms.ToTensor(),                # Convert the image to a tensor
#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image
# ])

# # Load the trained model
# model = ConvolutionalNetwork.load_from_checkpoint("main_model.ckpt")
# model.eval()  # Set the model to evaluation mode

# # Function to perform inference on internet images
# def predict_image_from_url(image_url):
#     # Download the image from the internet
#     response = requests.get(image_url)
#     img = Image.open(BytesIO(response.content))

#     # Convert the image to RGB mode (if grayscale)
#     if img.mode != "RGB":
#         img = img.convert("RGB")

#     # Apply transformations
#     img = transform_internet(img).unsqueeze(0)  # Add batch dimension

#     # Perform inference
#     with torch.no_grad():
#         output = model(img)
#         probabilities = torch.exp(output)
#         predicted_class = torch.argmax(probabilities).item()

#     return predicted_class, probabilities

# # Internet image URL
# # internet_image_url = "https://storage.googleapis.com/kagglesdsdata/datasets/4327199/7435304/Rice%20Leaf%20Disease%20Dataset/brown_spot/Brown_spot%20%28105%29.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20240211%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240211T070413Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=9052360546b56ad903aa4e46c24685b1539db7e98158decc9cc02c486fd958789e8d6c7ea91d7fac7d7e0aaa9a560a55d8ff7a1e773114c988b559ec3d0ec139329de7aaef4c293eac7dbf87d1d9a70920e0c879000e7111babaf6b7015fa937d448c6c7479bfbe8f22995a9ec80f5f5314d60a6461b0bf21123c12ea503ba7becd684ab75450d2d1fcbe0dd0172d60b65fa46a8b7d0faf52b264e5115120930da737864894e49552d2e4fd5cd125096eca508df388bed0521a7ad79b13bbe44a0e3748eed4f23604f82fdb02eaadc0a566eea8b2e8334f76ee411413d71a9ea460906875c4e2cb4b03440866b094c89ec5764e296bc835649387f3181fd7507"

# # Perform inference
# predicted_class, probabilities = predict_image_from_url(internet_image_url)

# # Convert probabilities tensor to percentages
# probabilities_percentage = (probabilities.squeeze() * 100).tolist()

# # Load the class labels
# class_labels = dataset.classes

# # Get the class label corresponding to the predicted class index
# class_label = class_labels[predicted_class]

# # Print results
# print("Predicted Class:", class_label)
# print("Probabilities (in percentage):")
# for label, prob in zip(class_labels, probabilities_percentage):
#     print(f"{label}: {prob:.3f}%")